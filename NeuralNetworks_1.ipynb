{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets,model_type):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        if model_type == 'classifier':\n",
    "            self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "        elif model_type == 'regressor':\n",
    "            self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "def scale_column(x_train:pd.DataFrame, x_test:pd.DataFrame, column:list):\n",
    "    \"\"\"\n",
    "    Move to utils_NN.py\n",
    "    Scales the same nature columns of x_train and x_test using the MinMaxScaler. The reference column is the one with the maximum value.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    max_value = x_train[column].max().max()\n",
    "    x_train[column] = x_train[column]/max_value\n",
    "    x_test[column]  = x_test[column]/max_value\n",
    "    return x_train, x_test, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "model_type =  'regressor' # 'classifier' or 'regressor'\n",
    "use_trap_info = True\n",
    "ntraps = 3\n",
    "lags = 3\n",
    "random_split = True\n",
    "test_size = 0.2\n",
    "scale = False\n",
    "learning_rate =1e-3\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'model_type': model_type,\n",
    "'use_trap_info': use_trap_info,\n",
    "'ntraps': ntraps,\n",
    "'lags': lags,\n",
    "'random_split': random_split,\n",
    "'test_size': test_size,\n",
    "'scale': scale,\n",
    "'learning_rate': learning_rate,\n",
    "'batch_size': batch_size,\n",
    "'epochs': epochs   \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import and preprocessing\n",
    "data = pd.read_csv(f'./results/final_df_lag{lags}_ntraps{ntraps}.csv')\n",
    "n = data.shape[0]\n",
    "nplaca_index = data['nplaca']\n",
    "data.drop(columns=['nplaca','distance0'], inplace=True) # drop distance0 because it is always zero\n",
    "ovos_flag = data['novos'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# divide columns into groups\n",
    "days_columns = [f'days{i}_lag{j}' for i in range(ntraps) for j in range(1, lags+1)]\n",
    "distance_columns = [f'distance{i}' for i in range(1,ntraps)]\n",
    "eggs_columns = [f'trap{i}_lag{j}' for i in range(ntraps) for j in range(1, lags+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of x and y\n",
    "if model_type == 'classifier':\n",
    "    y = ovos_flag\n",
    "elif model_type == 'regressor':\n",
    "    y = data['novos']\n",
    "\n",
    "if use_trap_info:\n",
    "    x = data.drop(columns=['novos'])\n",
    "else:\n",
    "    drop_cols = ['novos'] + days_columns + distance_columns\n",
    "    x = data.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_size = 1 - test_size\n",
    "\n",
    "if random_split:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=42, stratify=ovos_flag)\n",
    "else:\n",
    "    y_train = y.iloc[:int(n*train_size)]\n",
    "    y_test = y.iloc[int(n*train_size):]\n",
    "    x_train = x.iloc[:int(n*train_size)]\n",
    "    x_test = x.iloc[int(n*train_size):]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "if scale:\n",
    "    x_train, x_test, max_eggs = scale_column(x_train, x_test, eggs_columns)\n",
    "    if use_trap_info:\n",
    "        x_train, x_test, max_distance = scale_column(x_train, x_test, distance_columns)\n",
    "        x_train, x_test, max_days = scale_column(x_train, x_test, days_columns)\n",
    "\n",
    "\n",
    "    if model_type != 'classifier':\n",
    "        y_train = y_train/max_eggs\n",
    "        y_test = y_test/max_eggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16112\\3919755799.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.features = torch.tensor(features, dtype=torch.float32)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16112\\3919755799.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets = torch.tensor(targets, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# transform to tensors\n",
    "xtrain = torch.tensor(x_train.values, dtype=torch.float32).to(device)\n",
    "xtest = torch.tensor(x_test.values, dtype=torch.float32).to(device)\n",
    "if model_type == 'classifier':\n",
    "    ytrain = torch.tensor(y_train.values, dtype=torch.long).to(device)\n",
    "    ytest = torch.tensor(y_test.values, dtype=torch.long).to(device)\n",
    "elif model_type == 'regressor':\n",
    "    ytrain = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "    ytest = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "    \n",
    "train_dataset = CustomDataset(xtrain, ytrain,model_type)\n",
    "test_dataset = CustomDataset(xtest, ytest,model_type)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=random_split)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=random_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network structure\n",
    "if use_trap_info:\n",
    "    model_input = lags*ntraps + ntraps-1 + ntraps*lags # sum  of eggs, distances minus one and days\n",
    "else:\n",
    "    model_input = lags*ntraps\n",
    "    \n",
    "if model_type == 'classifier':\n",
    "    model_output = 2\n",
    "elif model_type == 'regressor':\n",
    "    model_output = 1\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.structure = nn.Sequential(\n",
    "            nn.Linear(model_input, 20),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.Linear(5, model_output)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.structure(x)\n",
    "        return logits    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test loops\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,batch_size):\n",
    "    size = xtrain.shape[0]\n",
    "    model.train()\n",
    "    for batch, (xtest, ytest) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xtest)\n",
    "        loss = loss_fn(pred, ytest)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(xtest)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn,model_type):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, acc = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            if model_type == 'classifier':\n",
    "                pred = model(X)\n",
    "                acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            elif model_type == 'regressor':\n",
    "                pred = torch.round(model(X))\n",
    "                acc += ((pred.round() == y).type(torch.float)).sum().item()\n",
    "\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    acc /= size\n",
    "    print(f\"Test Metrics: \\n Accuracy: {(100*acc):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4653.574219  [   64/267656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\miniconda3\\envs\\venv_ovitraps\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2225.621338  [ 6464/267656]\n",
      "loss: 4686.448242  [12864/267656]\n",
      "loss: 4635.913086  [19264/267656]\n",
      "loss: 3015.839355  [25664/267656]\n",
      "loss: 3711.317871  [32064/267656]\n",
      "loss: 60772.812500  [38464/267656]\n",
      "loss: 2462.866211  [44864/267656]\n",
      "loss: 3956.755615  [51264/267656]\n",
      "loss: 4601.730957  [57664/267656]\n",
      "loss: 10129.496094  [64064/267656]\n",
      "loss: 11949.902344  [70464/267656]\n",
      "loss: 4189.386719  [76864/267656]\n",
      "loss: 2557.769775  [83264/267656]\n",
      "loss: 4199.195312  [89664/267656]\n",
      "loss: 6696.571777  [96064/267656]\n",
      "loss: 7039.033203  [102464/267656]\n",
      "loss: 1585.639893  [108864/267656]\n",
      "loss: 3773.840332  [115264/267656]\n",
      "loss: 4470.018555  [121664/267656]\n",
      "loss: 2304.821777  [128064/267656]\n",
      "loss: 1234.786621  [134464/267656]\n",
      "loss: 4509.984375  [140864/267656]\n",
      "loss: 2602.822021  [147264/267656]\n",
      "loss: 6723.731445  [153664/267656]\n",
      "loss: 3756.863037  [160064/267656]\n",
      "loss: 1067.533691  [166464/267656]\n",
      "loss: 3017.060059  [172864/267656]\n",
      "loss: 2888.207764  [179264/267656]\n",
      "loss: 34433.941406  [185664/267656]\n",
      "loss: 1445.730835  [192064/267656]\n",
      "loss: 11387.288086  [198464/267656]\n",
      "loss: 1109.668701  [204864/267656]\n",
      "loss: 1686.621948  [211264/267656]\n",
      "loss: 4674.774414  [217664/267656]\n",
      "loss: 1626.312622  [224064/267656]\n",
      "loss: 43417.683594  [230464/267656]\n",
      "loss: 3193.518555  [236864/267656]\n",
      "loss: 3730.260010  [243264/267656]\n",
      "loss: 24266.800781  [249664/267656]\n",
      "loss: 2810.485596  [256064/267656]\n",
      "loss: 4972.845703  [262464/267656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\miniconda3\\envs\\venv_ovitraps\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\User\\miniconda3\\envs\\venv_ovitraps\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([34])) that is different to the input size (torch.Size([34, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: \n",
      " Accuracy: 31.7%, Avg loss: 41943.466846 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "if model_type == 'classifier':\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "elif model_type == 'regressor':\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "loss_hist = []\n",
    "accuracy_hist = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, batch_size)\n",
    "    acc, test_loss = test_loop(test_dataloader, model, loss_fn,model_type)\n",
    "    \n",
    "    accuracy_hist.append(acc)\n",
    "    loss_hist.append(test_loss)\n",
    "    torch.save(model.state_dict(), f'./results/NN/save_parameters/model{model_type}_lags{lags}_ntraps{3}_epoch{t}.pth')\n",
    "    \n",
    "    \n",
    "print(\"Done!\")\n",
    "utils.play_ending_song()\n",
    "utils.stop_ending_song(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'classifier':\n",
    "    yhat = model(xtest).argmax(1).cpu().numpy()\n",
    "elif model_type == 'regressor':\n",
    "    yhat = model(xtest).round().cpu().detach().numpy() \n",
    "\n",
    "if model_type == 'classifier':\n",
    "    print(accuracy_score(y_test, yhat))\n",
    "    print(confusion_matrix(y_test, yhat, normalize='true', labels=[0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_path = f'./results/NN/save_structure/model{model_type}_lags{lags}_ntraps{3}_structure.pth'\n",
    "torch.save(model, structure_path)\n",
    "\n",
    "new_results = {\n",
    "    'model': model_type,\n",
    "    'net_structure': structure_path,\n",
    "    'repetition': 1,\n",
    "    'parameters': parameters,\n",
    "    'date': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'accuracy': accuracy_hist,\n",
    "    'loss': loss_hist,\n",
    "    'yhat': yhat.tolist(),\n",
    "    'ytest': ytest.cpu().numpy().tolist(),\n",
    "}\n",
    "\n",
    "\n",
    "# Load the existing JSON file\n",
    "with open('./results/NN/model_accuracies.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "    # Update with new results\n",
    "\n",
    "\n",
    "for item in results:\n",
    "    if item['parameters'] == new_results['parameters'] and item['net_structure'] == new_results['net_structure']:\n",
    "        new_results['repetition'] = item['repetition'] + 1\n",
    "results.append(new_results)\n",
    "\n",
    "\n",
    "\n",
    "with open('./results/NN/model_accuracies.json', 'w') as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the existing JSON file\n",
    "with open('./results/NN/model_accuracies.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "    # Update with new results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xtest).round() == ytest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ovitraps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
